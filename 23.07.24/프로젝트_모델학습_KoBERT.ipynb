{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMDjSoMLFfOQSz4OlChnSuq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jason96819/Project_1/blob/main/23.07.24/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8_%EB%AA%A8%EB%8D%B8%ED%95%99%EC%8A%B5_KoBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 : https://github.com/kiyoungkim1/LMkor"
      ],
      "metadata": {
        "id": "A6jjtqGls9L5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Korpora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9NsoMQNHOuj",
        "outputId": "89d7f07c-82b1-4a30-d06f-58d00564b71d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Korpora in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: dataclasses>=0.6 in /usr/local/lib/python3.10/dist-packages (from Korpora) (0.6)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from Korpora) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.46.0 in /usr/local/lib/python3.10/dist-packages (from Korpora) (4.65.0)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from Korpora) (2.27.1)\n",
            "Requirement already satisfied: xlrd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from Korpora) (2.0.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->Korpora) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->Korpora) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->Korpora) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->Korpora) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1lXUfl8YOQN",
        "outputId": "defe90af-5eb8-4d3d-e826-8d124c937021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 한글 자연어 처리 데이터셋\n",
        "from Korpora import Korpora\n",
        "\n",
        "# 토크나이저 관련 경고 무시하기 위하여 설정\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = 'true'\n",
        "\n",
        "# device 지정\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'사용 디바이스: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8eyGaZAG-LL",
        "outputId": "08cb8180-7eb4-4744-ef06-f88759fe25ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사용 디바이스: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv('~/Korpora/nsmc/ratings_train.txt', sep='\\t')\n",
        "test = pd.read_csv('~/Korpora/nsmc/ratings_test.txt', sep='\\t')\n",
        "train['length'] = train['document'].apply(lambda x: len(str(x)))\n",
        "test['length'] = test['document'].apply(lambda x: len(str(x)))\n",
        "train = train.loc[train['length'] > 5]\n",
        "test = test.loc[test['length'] > 5]"
      ],
      "metadata": {
        "id": "vH33oGn_G-Gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import urllib.request\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/bab2min/corpus/master/sentiment/steam.txt\", filename=\"steam.txt\")\n",
        "total_data = pd.read_table('steam.txt', names=['label', 'document'])\n",
        "total_data.drop_duplicates(subset=['document'], inplace=True)\n",
        "train, test = train_test_split(total_data, test_size = 0.25, random_state = 77)\n",
        "train['length'] = train['document'].apply(lambda x: len(str(x)))\n",
        "test['length'] = test['document'].apply(lambda x: len(str(x)))\n",
        "train = train.loc[train['length'] > 5]\n",
        "test = test.loc[test['length'] > 5]"
      ],
      "metadata": {
        "id": "yaVQ8uQW84bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.reset_index()\n",
        "train.rename(columns={'index':'id'}, inplace=True)\n",
        "\n",
        "test = test.reset_index()\n",
        "test.rename(columns={'index':'id'}, inplace=True)"
      ],
      "metadata": {
        "id": "syEy9qnE-wBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CHECKPOINT_NAME = 'kykim/bert-kor-base'"
      ],
      "metadata": {
        "id": "iCkA5m3XIqtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizerFast\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class TokenDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer_pretrained):\n",
        "        # sentence, label 컬럼으로 구성된 데이터프레임 전달\n",
        "        self.data = dataframe\n",
        "        # Huggingface 토크나이저 생성\n",
        "        self.tokenizer = BertTokenizerFast.from_pretrained(tokenizer_pretrained)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = self.data.iloc[idx]['document']\n",
        "        label = self.data.iloc[idx]['label']\n",
        "\n",
        "        # 토큰화 처리\n",
        "        tokens = self.tokenizer(\n",
        "            sentence,                # 1개 문장\n",
        "            return_tensors='pt',     # 텐서로 반환\n",
        "            truncation=True,         # 잘라내기 적용\n",
        "            padding='max_length',    # 패딩 적용\n",
        "            add_special_tokens=True  # 스페셜 토큰 적용\n",
        "        )\n",
        "\n",
        "        input_ids = tokens['input_ids'].squeeze(0)           # 2D -> 1D\n",
        "        attention_mask = tokens['attention_mask'].squeeze(0) # 2D -> 1D\n",
        "        token_type_ids = torch.zeros_like(attention_mask)\n",
        "\n",
        "        # input_ids, attention_mask, token_type_ids 이렇게 3가지 요소를 반환하도록 합니다.\n",
        "        # input_ids: 토큰\n",
        "        # attention_mask: 실제 단어가 존재하면 1, 패딩이면 0 (패딩은 0이 아닐 수 있습니다)\n",
        "        # token_type_ids: 문장을 구분하는 id. 단일 문장인 경우에는 전부 0\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'token_type_ids': token_type_ids,\n",
        "        }, torch.tensor(label)"
      ],
      "metadata": {
        "id": "w_XCVHfFI1Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 토크나이저 지정\n",
        "tokenizer_pretrained = CHECKPOINT_NAME\n",
        "\n",
        "# train, test 데이터셋 생성\n",
        "train_data = TokenDataset(train, tokenizer_pretrained)\n",
        "test_data = TokenDataset(test, tokenizer_pretrained)\n",
        "\n",
        "# DataLoader로 이전에 생성한 Dataset를 지정하여, batch 구성, shuffle, num_workers 등을 설정합니다.\n",
        "train_loader = DataLoader(train_data, batch_size=8, shuffle=True, num_workers=8)\n",
        "test_loader = DataLoader(test_data, batch_size=8, shuffle=True, num_workers=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XGGSk0JI1NX",
        "outputId": "ea8af9cb-e99f-4dee-9ee7-c1deef3ff1db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1개의 batch 꺼내기\n",
        "inputs, labels = next(iter(train_loader))\n",
        "\n",
        "# 데이터셋을 device 설정\n",
        "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "labels.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wymIXj3EI1LH",
        "outputId": "f11660e8-12ee-4180-e5b9-3aed86815371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 생성된 inputs의 key 값 출력\n",
        "inputs.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWiZIWfvQ1Ap",
        "outputId": "6a06564a-3c5b-4797-867d-72c39d497924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask', 'token_type_ids'])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# key 별 shape 확인\n",
        "inputs['input_ids'].shape, inputs['attention_mask'].shape, inputs['token_type_ids'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wblBhbIhQ3ia",
        "outputId": "1854c38d-c5c4-4556-dbe4-189a24b36b53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([8, 512]), torch.Size([8, 512]), torch.Size([8, 512]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertConfig\n",
        "\n",
        "config = BertConfig.from_pretrained(CHECKPOINT_NAME)\n",
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrAT_VWVQ3ga",
        "outputId": "de90e63d-0e28-4249-cd65-2b85724ca055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  \"architectures\": [\n",
              "    \"BertForMaskedLM\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"directionality\": \"bidi\",\n",
              "  \"embedding_size\": 768,\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"model_type\": \"bert\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"pooler_fc_size\": 768,\n",
              "  \"pooler_num_attention_heads\": 12,\n",
              "  \"pooler_num_fc_layers\": 3,\n",
              "  \"pooler_size_per_head\": 128,\n",
              "  \"pooler_type\": \"first_token_transform\",\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"transformers_version\": \"4.31.0\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 42000\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# labels 출력\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2wah_OWQ3dp",
        "outputId": "350c7c43-6ef3-4fad-da3d-bd40cc113087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "# 모델 생성\n",
        "model_bert = BertModel.from_pretrained(CHECKPOINT_NAME).to(device)\n",
        "model_bert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koe3sVf2Q3bR",
        "outputId": "6c620b87-8ecf-40f0-8112-92cc4d412e67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(42000, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model_bert(**inputs)\n",
        "output.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2dVoUKKQ3U5",
        "outputId": "7c8bae3c-7e46-46fb-83b0-7ab544f2fe60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['last_hidden_state', 'pooler_output'])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output['last_hidden_state'].shape, output['pooler_output'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtfRnTOoQ9ry",
        "outputId": "951c27e4-a611-4a33-ce0c-558fa51fe1af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([8, 512, 768]), torch.Size([8, 768]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# last_hidden_state 출력\n",
        "last_hidden_state = output['last_hidden_state']\n",
        "print(last_hidden_state.shape)\n",
        "print(last_hidden_state[:, 0, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuH3BUb_Q9nE",
        "outputId": "5e33e2e4-e7e7-4473-d6c0-cf557fdfb891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 512, 768])\n",
            "tensor([[ 0.1999, -0.1813,  0.5653,  ...,  0.3027, -0.9701,  0.3158],\n",
            "        [ 0.2365,  0.0599, -1.1378,  ..., -0.1117, -0.8479,  0.1978],\n",
            "        [ 0.9883, -0.5612,  0.2901,  ...,  0.1757, -2.1688,  0.6170],\n",
            "        ...,\n",
            "        [ 0.7369, -0.4589, -0.1148,  ..., -0.0931, -1.7885,  1.0373],\n",
            "        [ 0.5184, -0.2614,  0.3263,  ...,  0.5617, -0.5520,  0.3053],\n",
            "        [-0.8319,  0.0792,  0.1243,  ..., -1.0170, -1.1717,  0.0999]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pooler_output 출력\n",
        "pooler_output = output['pooler_output']\n",
        "print(pooler_output.shape)\n",
        "print(pooler_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4CDSpO0Q9ky",
        "outputId": "e9f8ca7e-a9eb-4bd2-e3d4-48168c7362e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 768])\n",
            "tensor([[-0.7367,  0.3707, -0.8225,  ..., -0.9447,  0.0431,  0.7340],\n",
            "        [-0.3771,  0.6339, -0.9968,  ...,  0.3327,  0.5387,  0.1317],\n",
            "        [-0.3310,  0.6496, -0.9939,  ..., -0.9815,  0.7647,  0.7381],\n",
            "        ...,\n",
            "        [-0.7388,  0.6043, -0.7561,  ..., -0.7921,  0.5870,  0.2323],\n",
            "        [-0.9264,  0.1918, -0.7926,  ...,  0.3427,  0.1238,  0.8081],\n",
            "        [ 0.9497, -0.1734, -0.9994,  ...,  0.8735,  0.5725,  0.0856]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fc = nn.Linear(768, 2)\n",
        "fc.to(device)\n",
        "fc_output = fc(last_hidden_state[:, 0, :])\n",
        "print(fc_output.shape)\n",
        "print(fc_output.argmax(dim=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiA7mBhUQ9iR",
        "outputId": "c6f20a4c-5a66-415a-d4d6-6ca6dc7aae93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 2])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomBertModel(nn.Module):\n",
        "    def __init__(self, bert_pretrained, dropout_rate=0.5):\n",
        "        # 부모클래스 초기화\n",
        "        super(CustomBertModel, self).__init__()\n",
        "        # 사전학습 모델 지정\n",
        "        self.bert = BertModel.from_pretrained(bert_pretrained)\n",
        "        # dropout 설정\n",
        "        self.dr = nn.Dropout(p=dropout_rate)\n",
        "        # 최종 출력층 정의\n",
        "        self.fc = nn.Linear(768, 2)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        # 입력을 pre-trained bert model 로 대입\n",
        "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        # 결과의 last_hidden_state 가져옴\n",
        "        last_hidden_state = output['last_hidden_state']\n",
        "        # last_hidden_state[:, 0, :]는 [CLS] 토큰을 가져옴\n",
        "        x = self.dr(last_hidden_state[:, 0, :])\n",
        "        # FC 을 거쳐 최종 출력\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "pVlCT_cQI1Iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CustomBertModel 생성\n",
        "bert = CustomBertModel(CHECKPOINT_NAME)\n",
        "bert.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knya-zG4KHNB",
        "outputId": "d6f11482-6c11-40cd-e7e0-3f5f088712ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomBertModel(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(42000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dr): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss 정의: CrossEntropyLoss\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# 옵티마이저 정의: bert.paramters()와 learning_rate 설정\n",
        "optimizer = optim.Adam(bert.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "c0erSNweKJ3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm  # Progress Bar 출력\n",
        "\n",
        "def model_train(model, data_loader, loss_fn, optimizer, device):\n",
        "    # 모델을 훈련모드로 설정합니다. training mode 일 때 Gradient 가 업데이트 됩니다. 반드시 train()으로 모드 변경을 해야 합니다.\n",
        "    model.train()\n",
        "\n",
        "    # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n",
        "    running_loss = 0\n",
        "    corr = 0\n",
        "    counts = 0\n",
        "\n",
        "    # 예쁘게 Progress Bar를 출력하면서 훈련 상태를 모니터링 하기 위하여 tqdm으로 래핑합니다.\n",
        "    prograss_bar = tqdm(data_loader, unit='batch', total=len(data_loader), mininterval=1)\n",
        "\n",
        "    # mini-batch 학습을 시작합니다.\n",
        "    for idx, (inputs, labels) in enumerate(prograss_bar):\n",
        "        # inputs, label 데이터를 device 에 올립니다. (cuda:0 혹은 cpu)\n",
        "        inputs = {k:v.to(device) for k, v in inputs.items()}\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # 누적 Gradient를 초기화 합니다.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward Propagation을 진행하여 결과를 얻습니다.\n",
        "        output = model(**inputs)\n",
        "\n",
        "        # 손실함수에 output, label 값을 대입하여 손실을 계산합니다.\n",
        "        loss = loss_fn(output, labels)\n",
        "\n",
        "        # 오차역전파(Back Propagation)을 진행하여 미분 값을 계산합니다.\n",
        "        loss.backward()\n",
        "\n",
        "        # 계산된 Gradient를 업데이트 합니다.\n",
        "        optimizer.step()\n",
        "\n",
        "        # output의 max(dim=1)은 max probability와 max index를 반환합니다.\n",
        "        # max probability는 무시하고, max index는 pred에 저장하여 label 값과 대조하여 정확도를 도출합니다.\n",
        "        _, pred = output.max(dim=1)\n",
        "\n",
        "        # pred.eq(lbl).sum() 은 정확히 맞춘 label의 합계를 계산합니다. item()은 tensor에서 값을 추출합니다.\n",
        "        # 합계는 corr 변수에 누적합니다.\n",
        "        corr += pred.eq(labels).sum().item()\n",
        "        counts += len(labels)\n",
        "\n",
        "        # loss 값은 1개 배치의 평균 손실(loss) 입니다. img.size(0)은 배치사이즈(batch size) 입니다.\n",
        "        # loss 와 img.size(0)를 곱하면 1개 배치의 전체 loss가 계산됩니다.\n",
        "        # 이를 누적한 뒤 Epoch 종료시 전체 데이터셋의 개수로 나누어 평균 loss를 산출합니다.\n",
        "        running_loss += loss.item() * labels.size(0)\n",
        "\n",
        "        # 프로그레스바에 학습 상황 업데이트\n",
        "        prograss_bar.set_description(f\"training loss: {running_loss/(idx+1):.5f}, training accuracy: {corr / counts:.5f}\")\n",
        "\n",
        "    # 누적된 정답수를 전체 개수로 나누어 주면 정확도가 산출됩니다.\n",
        "    acc = corr / len(data_loader.dataset)\n",
        "\n",
        "    # 평균 손실(loss)과 정확도를 반환합니다.\n",
        "    # train_loss, train_acc\n",
        "    return running_loss / len(data_loader.dataset), acc"
      ],
      "metadata": {
        "id": "6hjN6a0aKOGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_evaluate(model, data_loader, loss_fn, device):\n",
        "    # model.eval()은 모델을 평가모드로 설정을 바꾸어 줍니다.\n",
        "    # dropout과 같은 layer의 역할 변경을 위하여 evaluation 진행시 꼭 필요한 절차 입니다.\n",
        "    model.eval()\n",
        "\n",
        "    # Gradient가 업데이트 되는 것을 방지 하기 위하여 반드시 필요합니다.\n",
        "    with torch.no_grad():\n",
        "        # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n",
        "        corr = 0\n",
        "        running_loss = 0\n",
        "\n",
        "        # 배치별 evaluation을 진행합니다.\n",
        "        for inputs, labels in data_loader:\n",
        "            # inputs, label 데이터를 device 에 올립니다. (cuda:0 혹은 cpu)\n",
        "            inputs = {k:v.to(device) for k, v in inputs.items()}\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # 모델에 Forward Propagation을 하여 결과를 도출합니다.\n",
        "            output = model(**inputs)\n",
        "\n",
        "            # output의 max(dim=1)은 max probability와 max index를 반환합니다.\n",
        "            # max probability는 무시하고, max index는 pred에 저장하여 label 값과 대조하여 정확도를 도출합니다.\n",
        "            _, pred = output.max(dim=1)\n",
        "\n",
        "            # pred.eq(lbl).sum() 은 정확히 맞춘 label의 합계를 계산합니다. item()은 tensor에서 값을 추출합니다.\n",
        "            # 합계는 corr 변수에 누적합니다.\n",
        "            corr += torch.sum(pred.eq(labels)).item()\n",
        "\n",
        "            # loss 값은 1개 배치의 평균 손실(loss) 입니다. img.size(0)은 배치사이즈(batch size) 입니다.\n",
        "            # loss 와 img.size(0)를 곱하면 1개 배치의 전체 loss가 계산됩니다.\n",
        "            # 이를 누적한 뒤 Epoch 종료시 전체 데이터셋의 개수로 나누어 평균 loss를 산출합니다.\n",
        "            running_loss += loss_fn(output, labels).item() * labels.size(0)\n",
        "\n",
        "        # validation 정확도를 계산합니다.\n",
        "        # 누적한 정답숫자를 전체 데이터셋의 숫자로 나누어 최종 accuracy를 산출합니다.\n",
        "        acc = corr / len(data_loader.dataset)\n",
        "\n",
        "        # 결과를 반환합니다.\n",
        "        # val_loss, val_acc\n",
        "        return running_loss / len(data_loader.dataset), acc"
      ],
      "metadata": {
        "id": "bK5aZVeFKSNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최대 Epoch을 지정합니다.\n",
        "num_epochs = 10\n",
        "\n",
        "# checkpoint로 저장할 모델의 이름을 정의 합니다.\n",
        "model_name = 'bert-kor-base'\n",
        "\n",
        "min_loss = np.inf\n",
        "\n",
        "# Epoch 별 훈련 및 검증을 수행합니다.\n",
        "for epoch in range(num_epochs):\n",
        "    # Model Training\n",
        "    # 훈련 손실과 정확도를 반환 받습니다.\n",
        "    train_loss, train_acc = model_train(bert, train_loader, loss_fn, optimizer, device)\n",
        "\n",
        "    # 검증 손실과 검증 정확도를 반환 받습니다.\n",
        "    val_loss, val_acc = model_evaluate(bert, test_loader, loss_fn, device)\n",
        "\n",
        "    # val_loss 가 개선되었다면 min_loss를 갱신하고 model의 가중치(weights)를 저장합니다.\n",
        "    if val_loss < min_loss:\n",
        "        print(f'[INFO] val_loss has been improved from {min_loss:.5f} to {val_loss:.5f}. Saving Model!')\n",
        "        min_loss = val_loss\n",
        "        torch.save(bert.state_dict(), f'{model_name}.pth')\n",
        "\n",
        "    # Epoch 별 결과를 출력합니다.\n",
        "    print(f'epoch {epoch+1:02d}, loss: {train_loss:.5f}, acc: {train_acc:.5f}, val_loss: {val_loss:.5f}, val_accuracy: {val_acc:.5f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T-Tgn8zKWi6",
        "outputId": "5a432bd3-5dd4-41bc-d91c-aeb09849310a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training loss: 3.19102, training accuracy: 0.82021: 100%|██████████| 9069/9069 [36:23<00:00,  4.15batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] val_loss has been improved from inf to 0.35732. Saving Model!\n",
            "epoch 01, loss: 0.39891, acc: 0.82021, val_loss: 0.35732, val_accuracy: 0.83651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training loss: 2.46690, training accuracy: 0.86822: 100%|██████████| 9069/9069 [36:25<00:00,  4.15batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] val_loss has been improved from 0.35732 to 0.35072. Saving Model!\n",
            "epoch 02, loss: 0.30839, acc: 0.86822, val_loss: 0.35072, val_accuracy: 0.84919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training loss: 1.82986, training accuracy: 0.90854: 100%|██████████| 9069/9069 [36:25<00:00,  4.15batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 03, loss: 0.22875, acc: 0.90854, val_loss: 0.37396, val_accuracy: 0.84522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training loss: 1.27520, training accuracy: 0.93950: 100%|██████████| 9069/9069 [36:25<00:00,  4.15batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 04, loss: 0.15941, acc: 0.93950, val_loss: 0.50007, val_accuracy: 0.84469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training loss: 0.87347, training accuracy: 0.96030: 100%|██████████| 9069/9069 [36:28<00:00,  4.14batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 05, loss: 0.10919, acc: 0.96030, val_loss: 0.75339, val_accuracy: 0.83878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training loss: 0.65004, training accuracy: 0.97050: 100%|██████████| 9069/9069 [36:29<00:00,  4.14batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 06, loss: 0.08126, acc: 0.97050, val_loss: 0.62752, val_accuracy: 0.83837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training loss: 0.49399, training accuracy: 0.97746: 100%|██████████| 9069/9069 [36:27<00:00,  4.15batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 07, loss: 0.06175, acc: 0.97746, val_loss: 0.65843, val_accuracy: 0.83853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training loss: 0.40897, training accuracy: 0.98211: 100%|██████████| 9069/9069 [36:27<00:00,  4.15batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 08, loss: 0.05113, acc: 0.98211, val_loss: 0.84440, val_accuracy: 0.84006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training loss: 0.35873, training accuracy: 0.98416: 100%|██████████| 9069/9069 [36:27<00:00,  4.15batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 09, loss: 0.04484, acc: 0.98416, val_loss: 0.81353, val_accuracy: 0.83097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training loss: 0.31017, training accuracy: 0.98591: 100%|██████████| 9069/9069 [36:26<00:00,  4.15batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10, loss: 0.03877, acc: 0.98591, val_loss: 0.91729, val_accuracy: 0.83733\n"
          ]
        }
      ]
    }
  ]
}